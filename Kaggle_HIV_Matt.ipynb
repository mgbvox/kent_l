{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j6fbpXm3YFNL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "pSQLJ2aIZAa2",
    "outputId": "27052bd3-3862-4c21-aa47-2911b5330445"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Resp</th>\n",
       "      <th>PR Seq</th>\n",
       "      <th>RT Seq</th>\n",
       "      <th>VL-t0</th>\n",
       "      <th>CD4-t0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>CCTCAAATCACTCTTTGGCAACGACCCCTCGTCCCAATAAGGATAG...</td>\n",
       "      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAGCTAAAGCCAGGAA...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAATAAAGATAG...</td>\n",
       "      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAATAAAGGTAG...</td>\n",
       "      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAATAAGGATAG...</td>\n",
       "      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...</td>\n",
       "      <td>5.7</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAGTAAAGATAG...</td>\n",
       "      <td>CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientID  Resp                                             PR Seq  \\\n",
       "0          1     0  CCTCAAATCACTCTTTGGCAACGACCCCTCGTCCCAATAAGGATAG...   \n",
       "1          2     0  CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAATAAAGATAG...   \n",
       "2          3     0  CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAATAAAGGTAG...   \n",
       "3          4     0  CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAATAAGGATAG...   \n",
       "4          5     0  CCTCAAATCACTCTTTGGCAACGACCCCTCGTCGCAGTAAAGATAG...   \n",
       "\n",
       "                                              RT Seq  VL-t0  CD4-t0  \n",
       "0  CCCATTAGTCCTATTGAAACTGTACCAGTAAAGCTAAAGCCAGGAA...    4.3     145  \n",
       "1  CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...    3.6     224  \n",
       "2  CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...    3.2    1017  \n",
       "3  CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...    5.7     206  \n",
       "4  CCCATTAGTCCTATTGAAACTGTACCAGTAAAATTAAAGCCAGGAA...    3.5     572  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at the data we've got:\n",
    "data = pd.read_csv('training_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1kVPpgRZZWmP",
    "outputId": "93b208a4-eae8-44eb-a101-8f590e341e34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PatientID', 'Resp', 'PR Seq', 'RT Seq', 'VL-t0', 'CD4-t0'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What are the columns?\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "WNIYw1pQdNDr",
    "outputId": "0ffa68f7-6e02-439a-947c-5364a7df4ad4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    794\n",
       "1    206\n",
       "Name: Resp, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How is the data distributed?\n",
    "data['Resp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "wQE4STsRdPxW",
    "outputId": "bc0acdc1-463b-46f5-d0f0-5f7497d2a87e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297    889\n",
       "294     14\n",
       "267      6\n",
       "270      3\n",
       "285      2\n",
       "252      2\n",
       "276      1\n",
       "261      1\n",
       "255      1\n",
       "216      1\n",
       "Name: PR Seq, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How do the sequences vary? This looks at length:\n",
    "\n",
    "data['PR Seq'].dropna().apply(lambda x: len(str(x))).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900     150\n",
       "909      93\n",
       "903      88\n",
       "1005     80\n",
       "750      74\n",
       "906      60\n",
       "897      23\n",
       "1464     22\n",
       "972      13\n",
       "1461     13\n",
       "912      13\n",
       "1452     12\n",
       "840       9\n",
       "1467      9\n",
       "876       9\n",
       "894       9\n",
       "783       9\n",
       "885       8\n",
       "801       8\n",
       "852       8\n",
       "855       8\n",
       "774       8\n",
       "1473      8\n",
       "1470      8\n",
       "1449      7\n",
       "1002      7\n",
       "888       7\n",
       "1476      7\n",
       "810       7\n",
       "1458      7\n",
       "       ... \n",
       "1074      1\n",
       "1098      1\n",
       "1347      1\n",
       "1110      1\n",
       "996       1\n",
       "705       1\n",
       "969       1\n",
       "966       1\n",
       "846       1\n",
       "837       1\n",
       "834       1\n",
       "828       1\n",
       "879       1\n",
       "819       1\n",
       "887       1\n",
       "795       1\n",
       "789       1\n",
       "896       1\n",
       "939       1\n",
       "744       1\n",
       "723       1\n",
       "672       1\n",
       "654       1\n",
       "597       1\n",
       "579       1\n",
       "1482      1\n",
       "1479      1\n",
       "951       1\n",
       "963       1\n",
       "1032      1\n",
       "Name: RT Seq, Length: 116, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What about the other sequence?\n",
    "data['RT Seq'].dropna().apply(lambda x: len(str(x))).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "XMEGtzVTe4_D",
    "outputId": "3ade9790-e260-4447-9a07-dbe16762c6cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11ac49ef0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#How is Viral Load and Response linked?\n",
    "data.plot.scatter('VL-t0', 'Resp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YV1QpGcYhJon"
   },
   "outputs": [],
   "source": [
    "#The above plot looks like the relationship follows\n",
    "#a logistic regression - this is common for binary \n",
    "#data (given Resp is either 0 or 1, we call the data binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rwIAF2Hphtvl",
    "outputId": "e5bb0546-949c-453e-d7a6-49f57c353c6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression Model: 78.7%\n"
     ]
    }
   ],
   "source": [
    "#Run a simple Logistic regression to predict\n",
    "#responsiveness from Viral Load and CD4 count:\n",
    "#(You can ignore the warnings this generates, if any.)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "X = data[['VL-t0', 'CD4-t0']]\n",
    "y = data['Resp']\n",
    "model.fit(X,y)\n",
    "y_pred = model.predict(X)\n",
    "acc = sum(data['Resp']==y_pred)/len(data['Resp'])\n",
    "print('Accuracy of Logistic Regression Model: {}%'.format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V3I_QFjZldTk"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "bEou-PCGlgc1",
    "outputId": "2f5b6a86-3005-4dd0-bfde-855ec1c0a710"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[758,  36],\n",
       "       [177,  29]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "o01Zzo6TlkUG",
    "outputId": "8050ebe0-9bcf-4631-e05d-d4bde8aacca6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2140221402214022"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Using just Viral Load and CD4 count, we have an okay model. We can do better.\\nThe next question: how to represent variable length sequences as fixed-length, numerical data?\\nAnswer: word2vec embeddings. A simple one is implemented below.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Using just Viral Load and CD4 count, we have an okay model. We can do better.\n",
    "The next question: how to represent variable length sequences as fixed-length, numerical data?\n",
    "Answer: word2vec embeddings. A simple one is implemented below.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/bb/56f295a604dfafdef746cc81081ff4c6e825690de95963000300a1cd3d80/gensim-3.7.3-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (24.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 24.7MB 1.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /Users/mgbvox/anaconda3/lib/python3.7/site-packages (from gensim) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /Users/mgbvox/anaconda3/lib/python3.7/site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/mgbvox/anaconda3/lib/python3.7/site-packages (from gensim) (1.15.4)\n",
      "Collecting smart-open>=1.7.0 (from gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/c0/25d19badc495428dec6a4bf7782de617ee0246a9211af75b302a2681dea7/smart_open-1.8.4.tar.gz (63kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 2.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: boto>=2.32 in /Users/mgbvox/anaconda3/lib/python3.7/site-packages (from smart-open>=1.7.0->gensim) (2.49.0)\n",
      "Requirement already satisfied: requests in /Users/mgbvox/anaconda3/lib/python3.7/site-packages (from smart-open>=1.7.0->gensim) (2.21.0)\n",
      "Collecting boto3 (from smart-open>=1.7.0->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/47/c7c92c453593a7b2a062bde3c5f714a4c5c12763f97b8b9c7a7480932bb1/boto3-1.9.167-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 2.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /Users/mgbvox/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.7.0->gensim) (2018.11.29)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/mgbvox/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.7.0->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/mgbvox/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.7.0->gensim) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/mgbvox/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.7.0->gensim) (1.24.1)\n",
      "Collecting botocore<1.13.0,>=1.12.167 (from boto3->smart-open>=1.7.0->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/00/8437c07663969bd219aab33299f17b9d0ecd82622f4e19f482483efbfc6d/botocore-1.12.167-py2.py3-none-any.whl (5.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.5MB 1.3MB/s \n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.7.0->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whl\n",
      "Collecting s3transfer<0.3.0,>=0.2.0 (from boto3->smart-open>=1.7.0->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/8a/1fc3dba0c4923c2a76e1ff0d52b305c44606da63f718d14d3231e21c51b0/s3transfer-0.2.1-py2.py3-none-any.whl (70kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 2.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /Users/mgbvox/anaconda3/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.167->boto3->smart-open>=1.7.0->gensim) (2.7.5)\n",
      "Requirement already satisfied: docutils>=0.10 in /Users/mgbvox/anaconda3/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.167->boto3->smart-open>=1.7.0->gensim) (0.14)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Running setup.py bdist_wheel for smart-open ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/mgbvox/Library/Caches/pip/wheels/5f/ea/fb/5b1a947b369724063b2617011f1540c44eb00e28c3d2ca8692\n",
      "Successfully built smart-open\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3, smart-open, gensim\n",
      "Successfully installed boto3-1.9.167 botocore-1.12.167 gensim-3.7.3 jmespath-0.9.4 s3transfer-0.2.1 smart-open-1.8.4\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CCTCAAATCACTCTTTGGCAACGACCCCTCGTCCCAATAAGGATAGGGGGGCAACTAAAGGAAGCYCTATTAGATACAGGAGCAGATGATACAGTATTAGAAGACATGGAGTTGCCAGGAAGATGGAAACCAAAAATGATAGGGGGAATTGGAGGTTTTATCAAAGTAARACAGTATGATCAGRTACCCATAGAAATCTATGGACATAAAGCTGTAGGTACAGTATTAATAGGACCTACACCTGTCAACATAATTGGAAGAAATCTGTTGACTCAGCTTGGTTGCACTTTAAATTTY'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T4yI8lOWl6ka"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b751bf047470>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mseq_to_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# define training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "def seq_to_cols(seq):\n",
    "    # define training data\n",
    "    sentences = seq.values\n",
    "    sentences = [[i] for i in sentences]\n",
    "    # train model\n",
    "    model = Word2Vec(sentences, min_count=1)\n",
    "    # summarize the loaded model\n",
    "    print(model)\n",
    "    # summarize vocabulary\n",
    "    words = list(model.wv.vocab)\n",
    "    #print(words)\n",
    "\n",
    "    # access vector for one word\n",
    "    #print(model[data['PR Seq'].dropna().values[0]].shape)\n",
    "\n",
    "    seq_name = '_'.join(seq.name.split(' '))\n",
    "\n",
    "    # save model\n",
    "    model.save('{}_model.bin'.format(seq_name))\n",
    "    \n",
    "    '''Not required - but here is how to load a model:\n",
    "    # load model\n",
    "    model = Word2Vec.load('{}_model.bin'.format(seq_name))\n",
    "    '''\n",
    "    \n",
    "    res_df = seq.apply(lambda x: model[x]).apply(pd.Series)\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=920, size=100, alpha=0.025)\n",
      "Word2Vec(vocab=920, size=100, alpha=0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mgb/anaconda3/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "/Users/mgb/anaconda3/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "/Users/mgb/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/Users/mgb/anaconda3/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "/Users/mgb/anaconda3/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "/Users/mgb/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "'''Embed each column - ignore the warnings.'''\n",
    "data = data.dropna(how='any')\n",
    "pr_df = seq_to_cols(data['PR Seq'])\n",
    "rt_df = seq_to_cols(data['RT Seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([pr_df,rt_df], axis=1)\n",
    "y = data['Resp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression Model: 79.67391304347827%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "model.fit(X,y)\n",
    "y_pred = model.predict(X)\n",
    "acc = sum(data['Resp']==y_pred)/len(data['Resp'])\n",
    "print('Accuracy of Logistic Regression Model: {}%'.format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[733,   0],\n",
       "       [187,   0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''More accurate, but it predicts all zeros:'''\n",
    "confusion_matrix(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Time to break out the big guns - Feed Forward Neural Networks!'''\n",
    "x_train = X\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mgb/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/mgb/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 736 samples, validate on 184 samples\n",
      "Epoch 1/100\n",
      "736/736 [==============================] - 0s 341us/step - loss: 0.6078 - acc: 0.8207 - val_loss: 0.6142 - val_acc: 0.7011\n",
      "Epoch 2/100\n",
      "736/736 [==============================] - 0s 28us/step - loss: 0.4739 - acc: 0.8207 - val_loss: 0.6639 - val_acc: 0.7011\n",
      "Epoch 3/100\n",
      "736/736 [==============================] - 0s 30us/step - loss: 0.4697 - acc: 0.8207 - val_loss: 0.6568 - val_acc: 0.7011\n",
      "Epoch 4/100\n",
      "736/736 [==============================] - 0s 31us/step - loss: 0.4684 - acc: 0.8207 - val_loss: 0.6585 - val_acc: 0.7011\n",
      "Epoch 5/100\n",
      "736/736 [==============================] - 0s 32us/step - loss: 0.4655 - acc: 0.8207 - val_loss: 0.6571 - val_acc: 0.7011\n",
      "Epoch 6/100\n",
      "736/736 [==============================] - 0s 37us/step - loss: 0.4640 - acc: 0.8207 - val_loss: 0.6598 - val_acc: 0.7011\n",
      "Epoch 7/100\n",
      "736/736 [==============================] - 0s 33us/step - loss: 0.4622 - acc: 0.8207 - val_loss: 0.6531 - val_acc: 0.7011\n",
      "Epoch 8/100\n",
      "736/736 [==============================] - 0s 37us/step - loss: 0.4618 - acc: 0.8207 - val_loss: 0.6516 - val_acc: 0.7011\n",
      "Epoch 9/100\n",
      "736/736 [==============================] - 0s 33us/step - loss: 0.4565 - acc: 0.8207 - val_loss: 0.6427 - val_acc: 0.7011\n",
      "Epoch 10/100\n",
      "736/736 [==============================] - 0s 31us/step - loss: 0.4522 - acc: 0.8207 - val_loss: 0.6709 - val_acc: 0.7011\n",
      "Epoch 11/100\n",
      "736/736 [==============================] - 0s 32us/step - loss: 0.4471 - acc: 0.8207 - val_loss: 0.6199 - val_acc: 0.7011\n",
      "Epoch 12/100\n",
      "736/736 [==============================] - 0s 28us/step - loss: 0.4480 - acc: 0.8207 - val_loss: 0.6678 - val_acc: 0.7011\n",
      "Epoch 13/100\n",
      "736/736 [==============================] - 0s 30us/step - loss: 0.4289 - acc: 0.8207 - val_loss: 0.6670 - val_acc: 0.7011\n",
      "Epoch 14/100\n",
      "736/736 [==============================] - 0s 30us/step - loss: 0.4173 - acc: 0.8207 - val_loss: 0.6857 - val_acc: 0.7011\n",
      "Epoch 15/100\n",
      "736/736 [==============================] - 0s 33us/step - loss: 0.4037 - acc: 0.8207 - val_loss: 0.6798 - val_acc: 0.7011\n",
      "Epoch 16/100\n",
      "736/736 [==============================] - 0s 36us/step - loss: 0.3937 - acc: 0.8207 - val_loss: 0.7326 - val_acc: 0.7011\n",
      "Epoch 17/100\n",
      "736/736 [==============================] - 0s 33us/step - loss: 0.3759 - acc: 0.8207 - val_loss: 0.7828 - val_acc: 0.7011\n",
      "Epoch 18/100\n",
      "736/736 [==============================] - 0s 34us/step - loss: 0.3610 - acc: 0.8247 - val_loss: 0.7935 - val_acc: 0.6793\n",
      "Epoch 19/100\n",
      "736/736 [==============================] - 0s 33us/step - loss: 0.3554 - acc: 0.8438 - val_loss: 0.8759 - val_acc: 0.6848\n",
      "Epoch 20/100\n",
      "736/736 [==============================] - 0s 33us/step - loss: 0.3482 - acc: 0.8438 - val_loss: 0.8868 - val_acc: 0.6793\n",
      "Epoch 21/100\n",
      "736/736 [==============================] - 0s 34us/step - loss: 0.3386 - acc: 0.8505 - val_loss: 0.9134 - val_acc: 0.6576\n",
      "Epoch 22/100\n",
      "736/736 [==============================] - 0s 33us/step - loss: 0.3313 - acc: 0.8573 - val_loss: 0.8663 - val_acc: 0.6413\n",
      "Epoch 23/100\n",
      "736/736 [==============================] - 0s 34us/step - loss: 0.3296 - acc: 0.8560 - val_loss: 0.9893 - val_acc: 0.6685\n",
      "Epoch 24/100\n",
      "736/736 [==============================] - 0s 33us/step - loss: 0.3219 - acc: 0.8587 - val_loss: 1.0461 - val_acc: 0.6793\n",
      "Epoch 25/100\n",
      "736/736 [==============================] - 0s 34us/step - loss: 0.3135 - acc: 0.8655 - val_loss: 1.0588 - val_acc: 0.6522\n",
      "Epoch 26/100\n",
      "736/736 [==============================] - 0s 35us/step - loss: 0.2995 - acc: 0.8682 - val_loss: 1.0466 - val_acc: 0.6522\n",
      "Epoch 27/100\n",
      "736/736 [==============================] - 0s 35us/step - loss: 0.3065 - acc: 0.8573 - val_loss: 1.1991 - val_acc: 0.6739\n",
      "Epoch 28/100\n",
      "736/736 [==============================] - 0s 38us/step - loss: 0.2928 - acc: 0.8736 - val_loss: 1.0878 - val_acc: 0.6467\n",
      "Epoch 29/100\n",
      "736/736 [==============================] - 0s 37us/step - loss: 0.2754 - acc: 0.8832 - val_loss: 1.1988 - val_acc: 0.6522\n",
      "Epoch 30/100\n",
      "736/736 [==============================] - 0s 37us/step - loss: 0.2683 - acc: 0.8859 - val_loss: 1.1848 - val_acc: 0.6304\n",
      "Epoch 31/100\n",
      "736/736 [==============================] - 0s 36us/step - loss: 0.2720 - acc: 0.8818 - val_loss: 1.2090 - val_acc: 0.6196\n",
      "Epoch 32/100\n",
      "736/736 [==============================] - 0s 31us/step - loss: 0.2576 - acc: 0.8995 - val_loss: 1.3037 - val_acc: 0.6467\n",
      "Epoch 33/100\n",
      "736/736 [==============================] - 0s 33us/step - loss: 0.2632 - acc: 0.8940 - val_loss: 1.1969 - val_acc: 0.5707\n",
      "Epoch 34/100\n",
      "736/736 [==============================] - 0s 32us/step - loss: 0.2349 - acc: 0.9117 - val_loss: 1.3428 - val_acc: 0.6196\n",
      "Epoch 35/100\n",
      "736/736 [==============================] - 0s 30us/step - loss: 0.2116 - acc: 0.9198 - val_loss: 1.3796 - val_acc: 0.6196\n",
      "Epoch 36/100\n",
      "736/736 [==============================] - 0s 28us/step - loss: 0.2097 - acc: 0.9348 - val_loss: 1.3917 - val_acc: 0.6033\n",
      "Epoch 37/100\n",
      "736/736 [==============================] - 0s 29us/step - loss: 0.1860 - acc: 0.9402 - val_loss: 1.6793 - val_acc: 0.6359\n",
      "Epoch 38/100\n",
      "736/736 [==============================] - 0s 31us/step - loss: 0.1683 - acc: 0.9511 - val_loss: 1.6754 - val_acc: 0.6359\n",
      "Epoch 39/100\n",
      "736/736 [==============================] - 0s 31us/step - loss: 0.1448 - acc: 0.9620 - val_loss: 1.7296 - val_acc: 0.6196\n",
      "Epoch 40/100\n",
      "736/736 [==============================] - 0s 30us/step - loss: 0.1270 - acc: 0.9701 - val_loss: 1.7116 - val_acc: 0.6141\n",
      "Epoch 41/100\n",
      "736/736 [==============================] - 0s 32us/step - loss: 0.1172 - acc: 0.9783 - val_loss: 1.9212 - val_acc: 0.6304\n",
      "Epoch 42/100\n",
      "736/736 [==============================] - 0s 31us/step - loss: 0.0988 - acc: 0.9783 - val_loss: 1.9329 - val_acc: 0.6304\n",
      "Epoch 43/100\n",
      "736/736 [==============================] - 0s 31us/step - loss: 0.0899 - acc: 0.9810 - val_loss: 2.0285 - val_acc: 0.6304\n",
      "Epoch 44/100\n",
      "736/736 [==============================] - 0s 32us/step - loss: 0.0761 - acc: 0.9851 - val_loss: 2.1723 - val_acc: 0.6359\n",
      "Epoch 45/100\n",
      "736/736 [==============================] - 0s 31us/step - loss: 0.0646 - acc: 0.9891 - val_loss: 2.2215 - val_acc: 0.6304\n",
      "Epoch 46/100\n",
      "736/736 [==============================] - 0s 32us/step - loss: 0.0569 - acc: 0.9891 - val_loss: 2.2884 - val_acc: 0.6359\n",
      "Epoch 47/100\n",
      "736/736 [==============================] - 0s 34us/step - loss: 0.0523 - acc: 0.9905 - val_loss: 2.4459 - val_acc: 0.6413\n",
      "Epoch 48/100\n",
      "736/736 [==============================] - 0s 35us/step - loss: 0.0496 - acc: 0.9905 - val_loss: 2.4077 - val_acc: 0.6304\n",
      "Epoch 49/100\n",
      "736/736 [==============================] - 0s 33us/step - loss: 0.0461 - acc: 0.9905 - val_loss: 2.5009 - val_acc: 0.6522\n",
      "Epoch 50/100\n",
      "736/736 [==============================] - 0s 34us/step - loss: 0.0442 - acc: 0.9905 - val_loss: 2.5483 - val_acc: 0.6413\n",
      "Epoch 51/100\n",
      "736/736 [==============================] - 0s 30us/step - loss: 0.0433 - acc: 0.9905 - val_loss: 2.6381 - val_acc: 0.6522\n",
      "Epoch 52/100\n",
      "736/736 [==============================] - 0s 30us/step - loss: 0.0421 - acc: 0.9905 - val_loss: 2.6127 - val_acc: 0.6467\n",
      "Epoch 53/100\n",
      "736/736 [==============================] - 0s 30us/step - loss: 0.0415 - acc: 0.9905 - val_loss: 2.7122 - val_acc: 0.6522\n",
      "Epoch 54/100\n",
      "736/736 [==============================] - 0s 30us/step - loss: 0.0407 - acc: 0.9905 - val_loss: 2.7424 - val_acc: 0.6522\n",
      "Epoch 55/100\n",
      "736/736 [==============================] - 0s 30us/step - loss: 0.0405 - acc: 0.9905 - val_loss: 2.6930 - val_acc: 0.6467\n",
      "Epoch 56/100\n",
      "736/736 [==============================] - 0s 29us/step - loss: 0.0402 - acc: 0.9905 - val_loss: 2.7526 - val_acc: 0.6522\n",
      "Epoch 57/100\n",
      "736/736 [==============================] - 0s 31us/step - loss: 0.0398 - acc: 0.9905 - val_loss: 2.7894 - val_acc: 0.6467\n",
      "Epoch 58/100\n",
      "736/736 [==============================] - 0s 29us/step - loss: 0.0395 - acc: 0.9905 - val_loss: 2.7845 - val_acc: 0.6467\n",
      "Epoch 59/100\n",
      "736/736 [==============================] - 0s 30us/step - loss: 0.0393 - acc: 0.9905 - val_loss: 2.8052 - val_acc: 0.6522\n",
      "Epoch 60/100\n",
      "736/736 [==============================] - 0s 31us/step - loss: 0.0394 - acc: 0.9905 - val_loss: 2.8346 - val_acc: 0.6522\n",
      "Epoch 61/100\n",
      "736/736 [==============================] - 0s 29us/step - loss: 0.0389 - acc: 0.9905 - val_loss: 2.8377 - val_acc: 0.6467\n",
      "Epoch 62/100\n",
      "736/736 [==============================] - 0s 31us/step - loss: 0.0387 - acc: 0.9905 - val_loss: 2.8790 - val_acc: 0.6522\n",
      "Epoch 63/100\n",
      "736/736 [==============================] - 0s 29us/step - loss: 0.0386 - acc: 0.9905 - val_loss: 2.8814 - val_acc: 0.6522\n",
      "Epoch 64/100\n",
      "736/736 [==============================] - 0s 30us/step - loss: 0.0387 - acc: 0.9905 - val_loss: 2.8630 - val_acc: 0.6467\n",
      "Epoch 65/100\n",
      "736/736 [==============================] - 0s 30us/step - loss: 0.0386 - acc: 0.9905 - val_loss: 2.9030 - val_acc: 0.6522\n",
      "Epoch 66/100\n",
      "736/736 [==============================] - 0s 31us/step - loss: 0.0375 - acc: 0.9905 - val_loss: 2.9028 - val_acc: 0.6467\n",
      "Epoch 67/100\n",
      "736/736 [==============================] - 0s 31us/step - loss: 0.0373 - acc: 0.9905 - val_loss: 2.8644 - val_acc: 0.6467\n",
      "Epoch 68/100\n",
      "736/736 [==============================] - 0s 36us/step - loss: 0.0327 - acc: 0.9918 - val_loss: 2.7855 - val_acc: 0.6413\n",
      "Epoch 69/100\n",
      "736/736 [==============================] - 0s 33us/step - loss: 0.0267 - acc: 0.9932 - val_loss: 2.8597 - val_acc: 0.6467\n",
      "Epoch 70/100\n",
      "736/736 [==============================] - 0s 35us/step - loss: 0.0221 - acc: 0.9959 - val_loss: 2.8153 - val_acc: 0.6304\n",
      "Epoch 71/100\n",
      "736/736 [==============================] - 0s 35us/step - loss: 0.0183 - acc: 0.9959 - val_loss: 2.9065 - val_acc: 0.6576\n",
      "Epoch 72/100\n",
      "736/736 [==============================] - 0s 34us/step - loss: 0.0139 - acc: 0.9986 - val_loss: 3.0032 - val_acc: 0.6630\n",
      "Epoch 73/100\n",
      "736/736 [==============================] - 0s 33us/step - loss: 0.0120 - acc: 0.9986 - val_loss: 3.0289 - val_acc: 0.6522\n",
      "Epoch 74/100\n",
      "736/736 [==============================] - 0s 38us/step - loss: 0.0109 - acc: 0.9986 - val_loss: 3.0797 - val_acc: 0.6685\n",
      "Epoch 75/100\n",
      "736/736 [==============================] - 0s 38us/step - loss: 0.0103 - acc: 0.9986 - val_loss: 3.1098 - val_acc: 0.6522\n",
      "Epoch 76/100\n",
      "736/736 [==============================] - 0s 37us/step - loss: 0.0099 - acc: 0.9986 - val_loss: 3.1317 - val_acc: 0.6413\n",
      "Epoch 77/100\n",
      "736/736 [==============================] - 0s 40us/step - loss: 0.0096 - acc: 0.9986 - val_loss: 3.1260 - val_acc: 0.6413\n",
      "Epoch 78/100\n",
      "736/736 [==============================] - 0s 36us/step - loss: 0.0093 - acc: 0.9986 - val_loss: 3.1889 - val_acc: 0.6576\n",
      "Epoch 79/100\n",
      "736/736 [==============================] - 0s 38us/step - loss: 0.0092 - acc: 0.9986 - val_loss: 3.1927 - val_acc: 0.6467\n",
      "Epoch 80/100\n",
      "736/736 [==============================] - 0s 35us/step - loss: 0.0090 - acc: 0.9986 - val_loss: 3.2291 - val_acc: 0.6630\n",
      "Epoch 81/100\n",
      "736/736 [==============================] - 0s 37us/step - loss: 0.0089 - acc: 0.9986 - val_loss: 3.2357 - val_acc: 0.6576\n",
      "Epoch 82/100\n",
      "736/736 [==============================] - 0s 37us/step - loss: 0.0088 - acc: 0.9986 - val_loss: 3.2438 - val_acc: 0.6576\n",
      "Epoch 83/100\n",
      "736/736 [==============================] - 0s 35us/step - loss: 0.0087 - acc: 0.9986 - val_loss: 3.2464 - val_acc: 0.6467\n",
      "Epoch 84/100\n",
      "736/736 [==============================] - 0s 34us/step - loss: 0.0087 - acc: 0.9986 - val_loss: 3.2753 - val_acc: 0.6576\n",
      "Epoch 85/100\n",
      "736/736 [==============================] - 0s 36us/step - loss: 0.0086 - acc: 0.9986 - val_loss: 3.2890 - val_acc: 0.6522\n",
      "Epoch 86/100\n",
      "736/736 [==============================] - 0s 35us/step - loss: 0.0085 - acc: 0.9986 - val_loss: 3.2793 - val_acc: 0.6522\n",
      "Epoch 87/100\n",
      "736/736 [==============================] - 0s 36us/step - loss: 0.0085 - acc: 0.9986 - val_loss: 3.2986 - val_acc: 0.6467\n",
      "Epoch 88/100\n",
      "736/736 [==============================] - 0s 36us/step - loss: 0.0085 - acc: 0.9986 - val_loss: 3.2903 - val_acc: 0.6413\n",
      "Epoch 89/100\n",
      "736/736 [==============================] - 0s 35us/step - loss: 0.0084 - acc: 0.9986 - val_loss: 3.3179 - val_acc: 0.6522\n",
      "Epoch 90/100\n",
      "736/736 [==============================] - 0s 36us/step - loss: 0.0084 - acc: 0.9986 - val_loss: 3.3199 - val_acc: 0.6522\n",
      "Epoch 91/100\n",
      "736/736 [==============================] - 0s 33us/step - loss: 0.0084 - acc: 0.9986 - val_loss: 3.3256 - val_acc: 0.6522\n",
      "Epoch 92/100\n",
      "736/736 [==============================] - 0s 33us/step - loss: 0.0083 - acc: 0.9986 - val_loss: 3.3341 - val_acc: 0.6522\n",
      "Epoch 93/100\n",
      "736/736 [==============================] - 0s 35us/step - loss: 0.0083 - acc: 0.9986 - val_loss: 3.3429 - val_acc: 0.6576\n",
      "Epoch 94/100\n",
      "736/736 [==============================] - 0s 36us/step - loss: 0.0083 - acc: 0.9986 - val_loss: 3.3418 - val_acc: 0.6522\n",
      "Epoch 95/100\n",
      "736/736 [==============================] - 0s 35us/step - loss: 0.0083 - acc: 0.9986 - val_loss: 3.3379 - val_acc: 0.6522\n",
      "Epoch 96/100\n",
      "736/736 [==============================] - 0s 35us/step - loss: 0.0082 - acc: 0.9986 - val_loss: 3.3563 - val_acc: 0.6576\n",
      "Epoch 97/100\n",
      "736/736 [==============================] - 0s 35us/step - loss: 0.0082 - acc: 0.9986 - val_loss: 3.3637 - val_acc: 0.6522\n",
      "Epoch 98/100\n",
      "736/736 [==============================] - 0s 34us/step - loss: 0.0082 - acc: 0.9986 - val_loss: 3.3575 - val_acc: 0.6522\n",
      "Epoch 99/100\n",
      "736/736 [==============================] - 0s 36us/step - loss: 0.0082 - acc: 0.9986 - val_loss: 3.3688 - val_acc: 0.6630\n",
      "Epoch 100/100\n",
      "736/736 [==============================] - 0s 35us/step - loss: 0.0082 - acc: 0.9986 - val_loss: 3.3778 - val_acc: 0.6522\n"
     ]
    }
   ],
   "source": [
    "'''Build, compile, and train a basic neural network on the provided data:'''\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation \n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(64, input_shape=x_train.values[0].shape, activation = 'relu'))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size = 32, epochs = 100, shuffle = True, validation_split=.2) #, validation_data = (x_valid, y_valid))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression Model: 92.93478260869566%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[707,  26],\n",
       "       [ 39, 148]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compare the results:\n",
    "y_pred = np.round(model.predict(x_train))\n",
    "y_real = y.apply(float).values\n",
    "\n",
    "acc = sum(data['Resp']==y_pred.ravel())/len(data['Resp'])\n",
    "print('Accuracy of Logistic Regression Model: {}%'.format(acc*100))\n",
    "\n",
    "confusion_matrix(y_real,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Better! Let's compare accuracy over training time for training and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa03cb74860>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oh.\n",
    "#We'll probably need to regularize, then. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Kaggle_HIV_Matt.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
