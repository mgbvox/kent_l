{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "'''Imports'''\n",
    "%pylab inline\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick wrapper method to make strings easier to work with.\n",
    "def rm_whitespace(s):\n",
    "    return ''.join(s.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, read in the data.\n",
    "data = pd.concat([pd.read_csv('training_data.csv'),pd.read_csv('test_data.csv')])\n",
    "data = data.dropna(how='any')\n",
    "\n",
    "#Log response types and gene types:\n",
    "response_types = [v for v in data['Resp'].unique() if type(v)==int]\n",
    "gene_types = [rm_whitespace(c) for c in data.columns if 'Seq' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_results = []\n",
    "all_muts = set()\n",
    "all_drug_classes = set()\n",
    "all_drugs = set()\n",
    "all_drug_scores = set()\n",
    "all_text_scores = set()\n",
    "\n",
    "all_results = []\n",
    "\n",
    "counter = 0\n",
    "for response_type in response_types:\n",
    "    for gene_type in gene_types:\n",
    "        f_name = './files/{}/{}'.format(response_type,gene_type)\n",
    "\n",
    "        gene_mutations = pd.DataFrame()\n",
    "        for f in os.listdir(f_name):\n",
    "            if '.DS_Store' not in f:\n",
    "                json_data = open('{}/{}/{}_seq.json'.format(f_name,f,f), 'r')\n",
    "                jdata = json.loads(json_data.read())\n",
    "                json_results.append(jdata)\n",
    "                \n",
    "                gene_type = jdata[0]['alignedGeneSequences'][0]['gene']['name']\n",
    "                \n",
    "                pairwise = jdata[0]['alignedGeneSequences'][0]['prettyPairwise']\n",
    "                aligned = jdata[0]['alignedGeneSequences'][0]\n",
    "                drugscores = jdata[0]['drugResistance'][0]['drugScores']\n",
    "                \n",
    "                #Get Nucleic Acids:\n",
    "                nas = aligned['alignedNAs']\n",
    "                #Get AAs:\n",
    "                aas = aligned['alignedAAs']\n",
    "                #Grab mutations at these locations\n",
    "                muts = pairwise['mutationLine']\n",
    "                \n",
    "                pos = pairwise['positionLine']\n",
    "                \n",
    "                res = [counter, response_type, gene_type, pos, nas, aas, muts]\n",
    "                \n",
    "                \n",
    "                for mut in muts:\n",
    "                    all_muts.add(mut)\n",
    "                for score in drugscores:\n",
    "                    dclass = score['drugClass']['name']\n",
    "                    drug = score['drug']['name']\n",
    "                    dscore = score['score']\n",
    "                    txt_score = score['text']\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    all_drug_classes.add(dclass)\n",
    "                    all_drugs.add(drug)\n",
    "                    all_drug_scores.add(dscore)\n",
    "                    all_text_scores.add(txt_score)\n",
    "                \n",
    "                res += [drugscores]\n",
    "                all_results.append(res)\n",
    "                \n",
    "            counter += 1\n",
    "            \n",
    "all_muts = sorted(list(all_muts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['counter', 'response_type', 'gene_type', 'pos', 'nas', 'aas', 'muts', 'drugscores']\n",
    "df = pd.DataFrame.from_records(all_results, columns=columns).drop('counter', axis=1)\n",
    "df = df[df['pos'].apply(lambda x: x[0]==' 1 ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = df[df['gene_type']=='PR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mgb/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "oh_muts = pr['muts'].apply(lambda x: \\\n",
    "                           np.array([[0 if mut != mut_type else 1 for mut_type in all_muts] for mut in x]).ravel())\n",
    "most_common_len = oh_muts.apply(len).value_counts().index[0]\n",
    "oh_muts = oh_muts[oh_muts.apply(len)==most_common_len]\n",
    "pr['oh_muts'] = oh_muts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = pr.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pr['oh_muts']\n",
    "x = np.stack(x)\n",
    "y = to_categorical(pr['response_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x[0].shape\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=input_shape, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(y[0].shape[0],activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.0001)\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "887/887 [==============================] - 2s 3ms/step - loss: 0.5653 - acc: 0.7993\n",
      "Epoch 2/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.5019 - acc: 0.7993\n",
      "Epoch 3/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.4956 - acc: 0.7993\n",
      "Epoch 4/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.4914 - acc: 0.7993\n",
      "Epoch 5/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.4850 - acc: 0.7993\n",
      "Epoch 6/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.4791 - acc: 0.7993\n",
      "Epoch 7/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.4707 - acc: 0.7993\n",
      "Epoch 8/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.4675 - acc: 0.7993\n",
      "Epoch 9/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.4543 - acc: 0.7993\n",
      "Epoch 10/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.4459 - acc: 0.7993\n",
      "Epoch 11/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.4365 - acc: 0.7993\n",
      "Epoch 12/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.4290 - acc: 0.7993\n",
      "Epoch 13/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.4157 - acc: 0.8005\n",
      "Epoch 14/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.4152 - acc: 0.8016\n",
      "Epoch 15/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.3997 - acc: 0.8016\n",
      "Epoch 16/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.3886 - acc: 0.8083\n",
      "Epoch 17/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.3781 - acc: 0.8072\n",
      "Epoch 18/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.3805 - acc: 0.8241\n",
      "Epoch 19/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.3675 - acc: 0.8264\n",
      "Epoch 20/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.3552 - acc: 0.8309\n",
      "Epoch 21/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.3427 - acc: 0.8444\n",
      "Epoch 22/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.3323 - acc: 0.8557\n",
      "Epoch 23/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.3456 - acc: 0.8377\n",
      "Epoch 24/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.3363 - acc: 0.8433\n",
      "Epoch 25/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.3225 - acc: 0.8568\n",
      "Epoch 26/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.3161 - acc: 0.8523\n",
      "Epoch 27/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.3034 - acc: 0.8681\n",
      "Epoch 28/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.2974 - acc: 0.8591\n",
      "Epoch 29/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.3086 - acc: 0.8681\n",
      "Epoch 30/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.2900 - acc: 0.8839\n",
      "Epoch 31/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.3192 - acc: 0.8557\n",
      "Epoch 32/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.2889 - acc: 0.8715\n",
      "Epoch 33/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.2803 - acc: 0.8816\n",
      "Epoch 34/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.2852 - acc: 0.8703\n",
      "Epoch 35/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.2772 - acc: 0.8771\n",
      "Epoch 36/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.2655 - acc: 0.8828\n",
      "Epoch 37/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.2631 - acc: 0.8850\n",
      "Epoch 38/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.2568 - acc: 0.8985\n",
      "Epoch 39/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.2839 - acc: 0.8771\n",
      "Epoch 40/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.2509 - acc: 0.8873\n",
      "Epoch 41/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.2559 - acc: 0.8940\n",
      "Epoch 42/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.2498 - acc: 0.8940\n",
      "Epoch 43/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.2604 - acc: 0.8906\n",
      "Epoch 44/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.2455 - acc: 0.8952\n",
      "Epoch 45/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.2410 - acc: 0.8952\n",
      "Epoch 46/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.2416 - acc: 0.8985\n",
      "Epoch 47/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.2342 - acc: 0.9019\n",
      "Epoch 48/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.2426 - acc: 0.8884\n",
      "Epoch 49/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.2293 - acc: 0.9019\n",
      "Epoch 50/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.2266 - acc: 0.9042\n",
      "Epoch 51/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.2267 - acc: 0.9042\n",
      "Epoch 52/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.2202 - acc: 0.9019\n",
      "Epoch 53/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.2182 - acc: 0.9030\n",
      "Epoch 54/100\n",
      "887/887 [==============================] - 2s 2ms/step - loss: 0.2165 - acc: 0.9076\n",
      "Epoch 55/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.2290 - acc: 0.8985\n",
      "Epoch 56/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.2209 - acc: 0.9042\n",
      "Epoch 57/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.2199 - acc: 0.9019\n",
      "Epoch 58/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.2114 - acc: 0.9143\n",
      "Epoch 59/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.2109 - acc: 0.9109\n",
      "Epoch 60/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.2266 - acc: 0.8974\n",
      "Epoch 61/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1978 - acc: 0.9166\n",
      "Epoch 62/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.2012 - acc: 0.9256\n",
      "Epoch 63/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.2398 - acc: 0.8974\n",
      "Epoch 64/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.2083 - acc: 0.9008\n",
      "Epoch 65/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1894 - acc: 0.9222\n",
      "Epoch 66/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1883 - acc: 0.9233\n",
      "Epoch 67/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.2011 - acc: 0.9064\n",
      "Epoch 68/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1831 - acc: 0.9267\n",
      "Epoch 69/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1923 - acc: 0.9200\n",
      "Epoch 70/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1698 - acc: 0.9324\n",
      "Epoch 71/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1902 - acc: 0.9154\n",
      "Epoch 72/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.1717 - acc: 0.9301\n",
      "Epoch 73/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1744 - acc: 0.9290\n",
      "Epoch 74/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1678 - acc: 0.9346\n",
      "Epoch 75/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1719 - acc: 0.9312\n",
      "Epoch 76/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1817 - acc: 0.9154\n",
      "Epoch 77/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.1597 - acc: 0.9436\n",
      "Epoch 78/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1627 - acc: 0.9335\n",
      "Epoch 79/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1642 - acc: 0.9335\n",
      "Epoch 80/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1541 - acc: 0.9436\n",
      "Epoch 81/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1456 - acc: 0.9459\n",
      "Epoch 82/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.1453 - acc: 0.9481\n",
      "Epoch 83/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1517 - acc: 0.9425\n",
      "Epoch 84/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1486 - acc: 0.9459\n",
      "Epoch 85/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1463 - acc: 0.9481\n",
      "Epoch 86/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1430 - acc: 0.9436\n",
      "Epoch 87/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.1338 - acc: 0.9526\n",
      "Epoch 88/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1286 - acc: 0.9526\n",
      "Epoch 89/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1276 - acc: 0.9583\n",
      "Epoch 90/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1310 - acc: 0.9538\n",
      "Epoch 91/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1232 - acc: 0.9560\n",
      "Epoch 92/100\n",
      "887/887 [==============================] - 2s 2ms/step - loss: 0.1250 - acc: 0.9526\n",
      "Epoch 93/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.1204 - acc: 0.9617\n",
      "Epoch 94/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1160 - acc: 0.9617\n",
      "Epoch 95/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1114 - acc: 0.9617\n",
      "Epoch 96/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1198 - acc: 0.9549\n",
      "Epoch 97/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1139 - acc: 0.9583\n",
      "Epoch 98/100\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 0.1151 - acc: 0.9538\n",
      "Epoch 99/100\n",
      "887/887 [==============================] - 2s 2ms/step - loss: 0.1095 - acc: 0.9605\n",
      "Epoch 100/100\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 0.1007 - acc: 0.9662\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x,y, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.99896765e-01 1.03246944e-04]]\n"
     ]
    }
   ],
   "source": [
    "def oh_mlist(mlist):\n",
    "    return(np.array([[0 if mut != mut_type else 1 for mut_type in all_muts] for mut in mlist]).ravel())\n",
    "\n",
    "for mlist in pr['muts'][0:1]:\n",
    "    orig_oh = np.expand_dims(oh_mlist(mlist), axis=0)\n",
    "    \n",
    "        \n",
    "    print(model.predict(np.stack(orig_oh)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 25938)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
